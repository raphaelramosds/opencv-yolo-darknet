{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbf362a6",
   "metadata": {},
   "source": [
    "# Detectando objetos com YOLO v4 e OpenCV\n",
    "\n",
    "## Visão geral\n",
    "\n",
    "No notebook anterior, utilizamos o framework Darknet para realizar a detecção de objetos em imagens com o You only look once (YOLO). Entretanto, também é possível empregar o módulo cv2, que corresponde à implementação do OpenCV em Python, para executar a mesma tarefa, sem a necessidade de compilar (buildar) o framework Darknet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79510f2c",
   "metadata": {},
   "source": [
    "## Etapa 1 - Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3e74d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.12.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32825917",
   "metadata": {},
   "source": [
    "## Etapa 2 - Conectando com o Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18e1b9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desnecessario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3369e9d",
   "metadata": {},
   "source": [
    "## Etapa 3 - Carregando os arquivos do modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55039d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yolov3(labels_path='/home/rapha/Projetos/opencv-yolo-darknet/shared/modelo_YOLOv3/coco.names', weights_path='/home/rapha/Projetos/opencv-yolo-darknet/shared/modelo_YOLOv3/yolov3.weights', config_path='/home/rapha/Projetos/opencv-yolo-darknet/shared/modelo_YOLOv3/yolov3.cfg', labels=['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "# Obter pesos, configuracao da arquitetura e labels da rede neural do modelo\n",
    "yolov3 = utils.carregar_yolov3()\n",
    "yolov3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7c7f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.dnn.Net 0x7f561d6aa5d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregar a rede YOLOv3 no módulo DNN (Deep Neural Network) do OpenCV\n",
    "net = cv2.dnn.readNet(yolov3.config_path, yolov3.weights_path)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f017dd73",
   "metadata": {},
   "source": [
    "Como é possível ver a seguir, uma rede neural pode ter mais de uma camada de saída, ou seja, camadas que recebem conexões da camada anterior, mas não se conectam a nenhuma camada seguinte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "410b4ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas as camadas: ('conv_0', 'bn_0', 'leaky_1', 'conv_1', 'bn_1', 'leaky_2', 'conv_2', 'bn_2', 'leaky_3', 'conv_3', 'bn_3', 'leaky_4', 'shortcut_4', 'conv_5', 'bn_5', 'leaky_6', 'conv_6', 'bn_6', 'leaky_7', 'conv_7', 'bn_7', 'leaky_8', 'shortcut_8', 'conv_9', 'bn_9', 'leaky_10', 'conv_10', 'bn_10', 'leaky_11', 'shortcut_11', 'conv_12', 'bn_12', 'leaky_13', 'conv_13', 'bn_13', 'leaky_14', 'conv_14', 'bn_14', 'leaky_15', 'shortcut_15', 'conv_16', 'bn_16', 'leaky_17', 'conv_17', 'bn_17', 'leaky_18', 'shortcut_18', 'conv_19', 'bn_19', 'leaky_20', 'conv_20', 'bn_20', 'leaky_21', 'shortcut_21', 'conv_22', 'bn_22', 'leaky_23', 'conv_23', 'bn_23', 'leaky_24', 'shortcut_24', 'conv_25', 'bn_25', 'leaky_26', 'conv_26', 'bn_26', 'leaky_27', 'shortcut_27', 'conv_28', 'bn_28', 'leaky_29', 'conv_29', 'bn_29', 'leaky_30', 'shortcut_30', 'conv_31', 'bn_31', 'leaky_32', 'conv_32', 'bn_32', 'leaky_33', 'shortcut_33', 'conv_34', 'bn_34', 'leaky_35', 'conv_35', 'bn_35', 'leaky_36', 'shortcut_36', 'conv_37', 'bn_37', 'leaky_38', 'conv_38', 'bn_38', 'leaky_39', 'conv_39', 'bn_39', 'leaky_40', 'shortcut_40', 'conv_41', 'bn_41', 'leaky_42', 'conv_42', 'bn_42', 'leaky_43', 'shortcut_43', 'conv_44', 'bn_44', 'leaky_45', 'conv_45', 'bn_45', 'leaky_46', 'shortcut_46', 'conv_47', 'bn_47', 'leaky_48', 'conv_48', 'bn_48', 'leaky_49', 'shortcut_49', 'conv_50', 'bn_50', 'leaky_51', 'conv_51', 'bn_51', 'leaky_52', 'shortcut_52', 'conv_53', 'bn_53', 'leaky_54', 'conv_54', 'bn_54', 'leaky_55', 'shortcut_55', 'conv_56', 'bn_56', 'leaky_57', 'conv_57', 'bn_57', 'leaky_58', 'shortcut_58', 'conv_59', 'bn_59', 'leaky_60', 'conv_60', 'bn_60', 'leaky_61', 'shortcut_61', 'conv_62', 'bn_62', 'leaky_63', 'conv_63', 'bn_63', 'leaky_64', 'conv_64', 'bn_64', 'leaky_65', 'shortcut_65', 'conv_66', 'bn_66', 'leaky_67', 'conv_67', 'bn_67', 'leaky_68', 'shortcut_68', 'conv_69', 'bn_69', 'leaky_70', 'conv_70', 'bn_70', 'leaky_71', 'shortcut_71', 'conv_72', 'bn_72', 'leaky_73', 'conv_73', 'bn_73', 'leaky_74', 'shortcut_74', 'conv_75', 'bn_75', 'leaky_76', 'conv_76', 'bn_76', 'leaky_77', 'conv_77', 'bn_77', 'leaky_78', 'conv_78', 'bn_78', 'leaky_79', 'conv_79', 'bn_79', 'leaky_80', 'conv_80', 'bn_80', 'leaky_81', 'conv_81', 'permute_82', 'yolo_82', 'identity_83', 'conv_84', 'bn_84', 'leaky_85', 'upsample_85', 'concat_86', 'conv_87', 'bn_87', 'leaky_88', 'conv_88', 'bn_88', 'leaky_89', 'conv_89', 'bn_89', 'leaky_90', 'conv_90', 'bn_90', 'leaky_91', 'conv_91', 'bn_91', 'leaky_92', 'conv_92', 'bn_92', 'leaky_93', 'conv_93', 'permute_94', 'yolo_94', 'identity_95', 'conv_96', 'bn_96', 'leaky_97', 'upsample_97', 'concat_98', 'conv_99', 'bn_99', 'leaky_100', 'conv_100', 'bn_100', 'leaky_101', 'conv_101', 'bn_101', 'leaky_102', 'conv_102', 'bn_102', 'leaky_103', 'conv_103', 'bn_103', 'leaky_104', 'conv_104', 'bn_104', 'leaky_105', 'conv_105', 'permute_106', 'yolo_106')\n",
      "Camadas de saída: ('yolo_82', 'yolo_94', 'yolo_106')\n",
      "Total de camadas: 254\n"
     ]
    }
   ],
   "source": [
    "# Lista com os identificadores (IDs) de todas as camadas da rede\n",
    "ln = net.getLayerNames()\n",
    "\n",
    "# Retorna os índices (baseados em 1) das camadas de saida\n",
    "ln_saida_indices = net.getUnconnectedOutLayers()\n",
    "\n",
    "# IDs das camadas de saída\n",
    "ln_saida_ids = tuple(ln[i - 1] for i in ln_saida_indices)\n",
    "\n",
    "print('Todas as camadas:', ln)\n",
    "print('Camadas de saída:', ln_saida_ids)\n",
    "print('Total de camadas: ' + str(len(ln)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749a92a3",
   "metadata": {},
   "source": [
    "**⚠️ ATENÇÃO:** o número de camadas de saída em uma CNN não deve ser confundido com o número de labels (classes) que o modelo é capaz de prever."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcbfc95",
   "metadata": {},
   "source": [
    "## Etapa 4 - Definindo mais configurações para a detecção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97650246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[181, 102, 140],\n",
       "       [ 65, 171,  66],\n",
       "       [224, 244,  19],\n",
       "       [243,  19, 177],\n",
       "       [ 56,  72, 101]], dtype=uint8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Gerar cores RGB aleatorias para \"colorir\" o contorno da caixa delimitadora de cada label/classe detectada\n",
    "# NOTE: o OpenCV trabalha com o sistema de cores BGR ao inves do RGB\n",
    "colors = np.random.randint(0, 255, size=(len(yolov3.labels), 3), dtype='uint8')\n",
    "colors[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv-yolo-darknet-OIo8HOCL-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
